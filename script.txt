Todo:

- add credits to technology intro slide
- add image credits to computer vision slide





----------------------------------------------------------------------------
-------- START



THANKS

- for the introduction
- for joining



So let's start with: what is ocean technology?




---------------------------------------------------------------------------
---------------------------  ocean technology slide


A variety of new emerging technologies are starting to transform ocean governance 


1. Ocean observation systems 
-- bring together different technologies
------- sensors, 
------- tracking devices
------- satellite remote sensing 
-- to monitor changing environmental conditions in the ocean
----- temperature changes
----- fish stocks
----- coral bleaching


2. Vessel monitoring systems 
-- for governments to track fishing boats


3. Video monitoring systems 
-- on fishing boats, using AI 


4. Lots of mobile apps for fishers 
- for things like collecting 

5. Increasingly complex and computationally intense models for fisheries management 

6. Technology for supply chain traceability 




-----------------------------------------------------------
--- internet access slide

But we know that the spread of computing technology hasn't been fair to everyone.

For example, internet access and device ownership haven't been fairly distributed. This map shows how broadband internet is much more easily available in some parts of the world than others, for example.

We also saw this during the covid-19 pandemic, when some people struggled with online education much more than others, because they didn't have reliable internet at home.



-------------------------------------------------------------
-- AI bias slide 

Another well-established problem is discriminatory biases in AI models. 

This example on the left illustrates how racism and misogyny are embedded in AI language models, which they learn from text on the internet.

We see similar problems in visual models. For example in one famous case, the passport application website for New Zealand was rejecting photos of Asian people because it thought their eyes were closed.

In this other example, researchers measured that Amazon's facial recognition product guessed the genders less accurately for black and brown women, tending to erroniously labeling them as men.

AI model biases are having more real-world impacts on people as they find their way into real products and applications.


--------------------------------------------------------
-- surveilance slide 

Another example, marginalized groups are disproportinately subjected to electronic surveillance, both online and offline, and often along lines of race, gender, and nationality.

Survailance systems are increasingly incorporating AI, too.


So given all these problems, how should we make sure that ocean technology is fair to everyone?


-------------------------------------------------------
-- equity triangle

We're taking the perspective that for ocean technology to be equitable, it must be anti-inequity. 

This intillectual foundation is based on Ibran X Kendi's work on antiracism. If you want to learn more about ocean equity, you can check out the Learning Forum on the Ocean Nexus Website.


-------------------------------------------------------------
-- outline slide 


So, here are some of the most important questions to consider for designing equitable ocean technology. 

1. In an ocean technology project, who has decision-making power?

2. Who is excluded? Either by technology access barriers, or by design factors.

3. Who benefits from model biases? This becoming more important with the rise of AI.

4. Who takes on burdens and risks? In an environmental technology project, these can be anything from extra work for some stakeholders, expenses, security and privacy risks, or reorganizing their institutions around the technology.

5. Who benefits from techno-optimism? 
-- By this I mean that technology is not the solution to every environmental problem, 
-- but technology tends to bring a lot of hype, excitement, and uncertianty.
-- Techno-optimism can draw attention away from other actions that we need. 
-- For example, there are a lot of robotic ocean-cleanup projects, but we really need regulation to stop plastic from ending up in the ocean in the first place, and it's argued that these ocean-cleanup projects are used to draw attention away from that.
-- Or, the exctitement and confusion around blockchain can allow some actors to claim that their fisheries supply chain is more tranceparent and traceable than it actually is.


Importantly, I'm not saying that ocean technology is bad or that we shouldn't do it.
- I'm saying that these are some conversations that we need to start having, in order to do it right.

- And this list is not exhaustive.


**TALK TOO LONG ON THIS SLIDE

FRAGMENT

For the rest of this presentation, I'm going to go into more detail and give some examples on three of these points; but unfortunately don't have time for all of them.

------------------------------------------- first signpost slide 

So first, let's talk about decision-making power in ocean technology projects.


------------------------------------------ model slide

On decision-making power, let's go into the example of modeling for fisheries management processes. 

Really complex and computationally-intensive models are becoming more and more common in different oceanic menagement processes. This slide has a couple diagrams to show how mind-bogglingly complex they are. 

More and more of these models require a lot of computational power. It's common for a model to take 2 weeks to run and produce a result on some heavy cloud infrastructure.



------------------------------------------- model problem slide


So what is the equity issue with modeling?

These ocean management models tend to get used in highly political and contested negotiation processes. 
- And the ever-increasing complexity of these models makes it harder for smaller, less-powerful stakeholders to participate. 

This is important because the models take a certain point of view: what is modeled and why? Some things are prioritized, other things left out. 
- These choices can be really political.
- When the models become so complicated, it has the effect of squeezing out less powerful stakeholders who have less technical capacity for modeling.

For some more depth, I'd like to refer you to Angela Abolhassani's work, an Ocean Nexus fellow, on how management procedures built on modeling frameworks can obscure these power imbalances.


There are a variety of "participatory modeling processes" that try to bridge this gap, but in practice they often fall short because the more powerful actors still keep control of the whole modelling process.

So, what do we do about this?

- There are some ways we can partially address this problem with technology changes, like using simpler models to lower the barrier to participation, or by building better interfaces with more connectivity.

--------------------------------------------- modeling decision-making-power slide



- However, technology changes alone are not enough to fix the core problem of who has the decision-making power.

Towards this point, I just want to flash you this diagram from Pedro Gonzalez-Espinosa's recent publication on equitable use of modelling in coral bleaching management, and refer you to that paper for a more detailed discussion of how to do this.



--------------------------------------------- signpost slide 

So now let's move to our next consideration for designing equitable ocean technologies: Who is excluded?

There are a few different ways that relying on technology can exclude some people from benefitting or participating.


----------------------------------------------- Pescadata slide

To talk about one of them, we'll use the example of PescaData, a mobile app for fishing cooperatives to manage data to get environmental certifications, among other features like connecting to other fishers.
- There are many other projects like this, so this gives us a case study.

A key goal of PescaData is to provide services to small and underserved fishing cooperatives.

However somewhat paradoxically, serving the most underserved fishing cooperatives is hard to do with a mobile app because these most-marginalized fishers often have the biggest barriers for using technology.

For example, many of the fishers had difficulties using the app, stemming from 
- mixed formal education levels
- and literacy barriers.
- These b arriers to using the app tended to fall along generational lines,
- as well as gender.
- Additionally, a access challenge for these fishing mobile app projects is that there just is not good cellular connectivity at sea.

More details from this analysis will be available soon in a forthcoming publication from Claudia Delgado Ram√≠rez.


So, what can you do about these technology access barriers?
- One is to center the most marginalized users in your design process. When you design specifically for the people who will have the most trouble with your app, then your other users tend to also benefit.

- Another is to use diverse communication channels; consider that not everybody will want to use your app, so you can use a multi-pronged strategy to meet people where they are.

- In some circumstances, it can help to invest in training for an app.



-------------------------------------------------------------
- online interactions slide

Another example I want to quickly point out is exclusion from online social spaces.

In Claudia's work on PescaData and fishing cooperatives, she found that lots of fishers had lively Facebook and Whatsapp groups, but they were largely gendered for only men or only women.

I also have a paper coming out soon where I interviewed staff of environmental organizations about community engagement, and they identified social stigmas as one of the main barriers. For example in some organizations where there were mixed languages, non-English speakers stopped participating because they felt excluded.

Sometimes these problems are addressable with careful design and moderation, but sometimes they're not.



----------------------------------------------------------
- signpost slide #3


Ok so now let's move onto the last topic for today, AI model biases. I think this is going to become really important soon, as we start to see more and more uses of AI in ocean governance.

There are a lot of different types of AI that all have different, but related problems.


------------------------------------- GPT store slide

So to introduce the problem, I want to start with the example of AI language models like ChatGPT.

What does ChatGPT have to do with ocean governance, you might ask?

It turns out that policymakers at the UN are using ChatGPT for all kinds of things already, like drafting statements for things and doing background research.

There are already commercial products on the market today that use AI language models for different types of policy analysis.

This screenshot is from OpanAI's "GPT Store," kind of like an app store for different custom versions of ChatGPT. A couple days ago I did a search for "environmental policy," and there are already all these different AI agents specialized for talking about environmental policy.



----------------------------------------------------
GPT bias slide 

****Wing it 


These models do have biases

----------------------------------------------------------- BBNJ chatbot slide 


To dig into this further, we made a chatbot about the UN Biodiversity Beyond National Jurisdiction Agreement and tested it out to examine AI Language Models' strengths, weaknesses, and equity psoblems for use in marine policy. You can find the preprint on archive.

In the paper, we examine ways that AI language models can help with some of the specific tedious parts of policy work, especially for smaller governments.

Of course though, we have some big concerns. In the paper we elaborate different causes of errors and biases in our BBNJ Chatbot, including 
- biases in GPT itself, which it learned from being trained on biased text from the Internet, newspapers, and books;
- biases from its connection to the BBNJ negotiation documents, which overrepresent the viewpoints of the developed countries,
- and biases stemming from the application design.

Still, we expect that generative AI is going to creep further and further into the policymaking process, and it's going to become important for people to develop more AI literacy to be able to get the most out of it while avoiding its pitfalls.

So, we've developed a workshop on "ChatGPT for policymaking practicioners." We presented it once with the Ocean Voices fellows, and I am really keen to present this to more groups so please get in touch if you're interested. We are also finishing up a website with all the material, so keep your eye out as we launch it in the next few weeks.



------------------------------------------------------ computer vision slide

Let's turn our attention to another AI application, computer vision. 

Computer vision is essentially when an AI program tries to understand what is going on in an image, like how social media apps automatically identify faces, for example. It essentially still works by training a model with lots of example pictures.

I think we are right on the cusp of computer vision becoming much more widespread in ocean management, very soon. The technology pretty recently became good enough to be useful, so there are lots of different applications in early-stage development that seem to be getting good results.

For example, there are projects using computer vision 
- to identify and count fish underwater as they go into a net
- to monitor onboard fishing boats, identifying and counting all the fish that get caught or thrown overboard, often also predicting their sex and age,
- and also lots of different applications using computer vision with sattelite images, like trying to identify fishing boats.


The bias issues with these models are a little different, but related.
- they will make errors sometimes, and the errors won't always be evenly distributed, possibly behaving unfairly to some people.
- since these uses of computer vision are all so new, we will likely need a lot of research into their equity, fairness, and accountability.

Fortunately there is some research in other sectors that we can build on as we figure this out, like critical technology research, algorithmic fairness, technology policy, et cetera.



----------------------------------------------------------------------
-- end slide


So this is the end of my slides and that's all we have time for today. 

Again, I'm not saying that ocean technologies are bad or that we shouldn't do them, but I think it's really important to have these conversations about equity. 

We can learn a lot from the hard-fought lessons in other technology sectors, hopefully avoid some mistakes, and strive to design ocean technology that is fair and equitable for everyone.

Now, I'll hand it over to Richard Anderson for his remarks.



HAND OFF TO RICHARD
